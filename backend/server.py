from fastapi import FastAPI, APIRouter, HTTPException
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime
from emergentintegrations.llm.chat import LlmChat, UserMessage


ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# MongoDB connection
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# LLM API Key
EMERGENT_LLM_KEY = os.environ.get('EMERGENT_LLM_KEY', '')

# Create the main app without a prefix
app = FastAPI()

# Create a router with the /api prefix
api_router = APIRouter(prefix="/api")


# Define Models
class StatusCheck(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    client_name: str
    timestamp: datetime = Field(default_factory=datetime.utcnow)

class StatusCheckCreate(BaseModel):
    client_name: str

# AI Analysis Models
class FinancialData(BaseModel):
    expenses: List[Dict[str, Any]]
    incomes: List[Dict[str, Any]]
    debts: List[Dict[str, Any]]
    budgets: List[Dict[str, Any]]
    savings_goals: List[Dict[str, Any]]
    recurring_expenses: List[Dict[str, Any]]
    currency: str = "TRY"

class AIAnalysisRequest(BaseModel):
    financial_data: FinancialData
    analysis_type: str = "full"  # full, spending, savings, forecast, tips

class AIAnalysisResponse(BaseModel):
    analysis: str
    insights: List[str]
    recommendations: List[str]
    spending_patterns: Optional[Dict[str, Any]] = None
    forecast: Optional[Dict[str, Any]] = None
    alerts: Optional[List[str]] = None

# Add your routes to the router instead of directly to app
@api_router.get("/")
async def root():
    return {"message": "Masrofi API - Ù…ØµØ±ÙˆÙÙŠ"}

# AI Analysis Endpoint
@api_router.post("/ai/analyze", response_model=AIAnalysisResponse)
async def analyze_finances(request: AIAnalysisRequest):
    """Analyze financial data using AI and provide insights"""
    try:
        if not EMERGENT_LLM_KEY:
            raise HTTPException(status_code=500, detail="AI service not configured")
        
        data = request.financial_data
        
        # Build context from financial data
        total_expenses = sum(e.get('amount', 0) for e in data.expenses)
        total_income = sum(i.get('amount', 0) for i in data.incomes)
        total_debts = sum(d.get('totalAmount', 0) for d in data.debts if d.get('status') == 'Ù†Ø´Ø·')
        total_savings = sum(s.get('currentAmount', 0) for s in data.savings_goals)
        total_recurring = sum(r.get('amount', 0) for r in data.recurring_expenses if r.get('isActive'))
        
        # Category breakdown
        category_spending = {}
        for exp in data.expenses:
            cat = exp.get('category', 'other')
            category_spending[cat] = category_spending.get(cat, 0) + exp.get('amount', 0)
        
        currency = data.currency
        
        # Create AI prompt
        prompt = f"""Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù…Ø§Ù„ÙŠ Ø°ÙƒÙŠ. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆÙ‚Ø¯Ù… Ù†ØµØ§Ø¦Ø­ Ù…ÙÙŠØ¯Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:

ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø§Ù„ÙŠ:
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¯Ø®Ù„: {total_income} {currency}
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØµØ±ÙˆÙØ§Øª: {total_expenses} {currency}
- Ø§Ù„Ø¯ÙŠÙˆÙ† Ø§Ù„Ù†Ø´Ø·Ø©: {total_debts} {currency}
- Ø§Ù„Ù…Ø¯Ø®Ø±Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {total_savings} {currency}
- Ø§Ù„Ù…ØµØ§Ø±ÙŠÙ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© Ø§Ù„Ø´Ù‡Ø±ÙŠØ©: {total_recurring} {currency}
- Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…ØªØ§Ø­: {total_income - total_expenses} {currency}

ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ØµØ±ÙˆÙØ§Øª Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©:
{chr(10).join([f"- {k}: {v} {currency}" for k, v in category_spending.items()])}

Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {len(data.expenses)}
Ø¹Ø¯Ø¯ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø§Ø¯Ø®Ø§Ø±: {len(data.savings_goals)}

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
1. ØªØ­Ù„ÙŠÙ„ Ù…ÙˆØ¬Ø² Ù„Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø§Ù„ÙŠ (3-4 Ø¬Ù…Ù„)
2. 3-5 Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø© (insights)
3. 3-5 ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ© Ù„Ù„ØªØ­Ø³ÙŠÙ†
4. Ø£ÙŠ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ù…Ù‡Ù…Ø© Ø¥Ù† ÙˆØ¬Ø¯Øª

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON:
{{
    "analysis": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù‡Ù†Ø§",
    "insights": ["Ù…Ù„Ø§Ø­Ø¸Ø© 1", "Ù…Ù„Ø§Ø­Ø¸Ø© 2"],
    "recommendations": ["ØªÙˆØµÙŠØ© 1", "ØªÙˆØµÙŠØ© 2"],
    "alerts": ["ØªÙ†Ø¨ÙŠÙ‡ 1"] Ø£Ùˆ []
}}"""

        # Initialize AI chat
        chat = LlmChat(
            api_key=EMERGENT_LLM_KEY,
            session_id=f"masrofi-analysis-{uuid.uuid4()}",
            system_message="Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù…Ø§Ù„ÙŠ Ù…Ø­ØªØ±Ù ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ ÙÙŠ Ø¥Ø¯Ø§Ø±Ø© Ø£Ù…ÙˆØ§Ù„Ù‡Ù…. Ù‚Ø¯Ù… Ù†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ© ÙˆÙ…ÙÙŠØ¯Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
        ).with_model("gemini", "gemini-2.5-flash")
        
        # Send message
        user_message = UserMessage(text=prompt)
        response_text = await chat.send_message(user_message)
        
        # Parse response
        import json
        import re
        
        # Try to extract JSON from response
        json_match = re.search(r'\{[\s\S]*\}', response_text)
        if json_match:
            try:
                parsed = json.loads(json_match.group())
                return AIAnalysisResponse(
                    analysis=parsed.get('analysis', response_text),
                    insights=parsed.get('insights', []),
                    recommendations=parsed.get('recommendations', []),
                    alerts=parsed.get('alerts', []),
                    spending_patterns=category_spending,
                    forecast={
                        "monthly_balance": total_income - total_expenses,
                        "savings_rate": round((total_savings / total_income * 100) if total_income > 0 else 0, 1),
                        "debt_ratio": round((total_debts / total_income * 100) if total_income > 0 else 0, 1),
                    }
                )
            except json.JSONDecodeError:
                pass
        
        # Fallback if JSON parsing fails
        return AIAnalysisResponse(
            analysis=response_text,
            insights=["ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„Ù…Ø§Ù„ÙŠØ©"],
            recommendations=["Ø§Ø³ØªÙ…Ø± ÙÙŠ ØªØªØ¨Ø¹ Ù…ØµØ§Ø±ÙŠÙÙƒ Ø¨Ø§Ù†ØªØ¸Ø§Ù…"],
            spending_patterns=category_spending,
            forecast={
                "monthly_balance": total_income - total_expenses,
            }
        )
        
    except Exception as e:
        logger.error(f"AI Analysis error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}")

# Quick Tips Endpoint
@api_router.post("/ai/tips")
async def get_quick_tips(request: AIAnalysisRequest):
    """Get quick financial tips based on data"""
    try:
        if not EMERGENT_LLM_KEY:
            raise HTTPException(status_code=500, detail="AI service not configured")
        
        data = request.financial_data
        total_expenses = sum(e.get('amount', 0) for e in data.expenses)
        total_income = sum(i.get('amount', 0) for i in data.incomes)
        
        prompt = f"""Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
- Ø¯Ø®Ù„Ù‡ Ø§Ù„Ø´Ù‡Ø±ÙŠ: {total_income} {data.currency}
- Ù…ØµØ±ÙˆÙØ§ØªÙ‡: {total_expenses} {data.currency}
- Ø¹Ø¯Ø¯ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÙ‡: {len(data.expenses)}

Ø£Ø¹Ø·Ù†ÙŠ 3 Ù†ØµØ§Ø¦Ø­ Ø³Ø±ÙŠØ¹Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (ÙƒÙ„ Ù†ØµÙŠØ­Ø© Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·). Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON:
{{"tips": ["Ù†ØµÙŠØ­Ø© 1", "Ù†ØµÙŠØ­Ø© 2", "Ù†ØµÙŠØ­Ø© 3"]}}"""

        chat = LlmChat(
            api_key=EMERGENT_LLM_KEY,
            session_id=f"masrofi-tips-{uuid.uuid4()}",
            system_message="Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù…Ø§Ù„ÙŠ. Ø£Ø¹Ø·Ù Ù†ØµØ§Ø¦Ø­ Ù‚ØµÙŠØ±Ø© ÙˆÙ…ÙÙŠØ¯Ø©."
        ).with_model("gemini", "gemini-2.5-flash")
        
        response_text = await chat.send_message(UserMessage(text=prompt))
        
        import json
        import re
        json_match = re.search(r'\{[\s\S]*\}', response_text)
        if json_match:
            try:
                parsed = json.loads(json_match.group())
                return {"tips": parsed.get('tips', [])}
            except:
                pass
        
        return {"tips": ["ØªØ§Ø¨Ø¹ Ù…ØµØ§Ø±ÙŠÙÙƒ ÙŠÙˆÙ…ÙŠØ§Ù‹", "Ø­Ø¯Ø¯ Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø´Ù‡Ø±ÙŠØ©", "Ø§Ø¯Ø®Ø± 20% Ù…Ù† Ø¯Ø®Ù„Ùƒ"]}
        
    except Exception as e:
        logger.error(f"Tips error: {str(e)}")
        return {"tips": ["ØªØ§Ø¨Ø¹ Ù…ØµØ§Ø±ÙŠÙÙƒ ÙŠÙˆÙ…ÙŠØ§Ù‹", "Ø­Ø¯Ø¯ Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø´Ù‡Ø±ÙŠØ©", "Ø§Ø¯Ø®Ø± 20% Ù…Ù† Ø¯Ø®Ù„Ùƒ"]}

@api_router.post("/status", response_model=StatusCheck)
async def create_status_check(input: StatusCheckCreate):
    status_dict = input.dict()
    status_obj = StatusCheck(**status_dict)
    _ = await db.status_checks.insert_one(status_obj.dict())
    return status_obj

@api_router.get("/status", response_model=List[StatusCheck])
async def get_status_checks(skip: int = 0, limit: int = 20):
    status_checks = await db.status_checks.find().skip(skip).limit(min(limit, 50)).to_list(50)
    return [StatusCheck(**status_check) for status_check in status_checks]

# Include the router in the main app
app.include_router(api_router)

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()
